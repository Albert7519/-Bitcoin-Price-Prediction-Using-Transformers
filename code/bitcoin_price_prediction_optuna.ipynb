{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Prequerities**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:15.421428Z",
     "iopub.status.busy": "2022-01-19T21:53:15.420705Z",
     "iopub.status.idle": "2022-01-19T21:53:30.212243Z",
     "shell.execute_reply": "2022-01-19T21:53:30.211347Z",
     "shell.execute_reply.started": "2022-01-19T21:53:15.421383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (1.4.5)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: torch in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from pandas==1.5.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from pandas==1.5.3) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from pandas==1.5.3) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.5 in c:\\users\\23695\\pycharmprojects\\-bitcoin-price-prediction-using-transformers\\.venv\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#installations\n",
    "\"\"\" !pip install finta \"\"\"\n",
    "!pip install torch-summary\n",
    "!pip install torch\n",
    "!pip install pandas==1.5.3\n",
    "%pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T13:21:45.608821Z",
     "start_time": "2025-02-01T13:21:44.677086Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.215902Z",
     "iopub.status.busy": "2022-01-19T21:53:30.215643Z",
     "iopub.status.idle": "2022-01-19T21:53:30.224277Z",
     "shell.execute_reply": "2022-01-19T21:53:30.223599Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.215869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# packages import\n",
    "# Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd \n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torchsummary import summary\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Finta\n",
    "from finta import TA\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "import torch.optim as optim\n",
    "\n",
    "# Others\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "CUDA version: 12.1\n",
      "GPU device count: 1\n",
      "GPU device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.226899Z",
     "iopub.status.busy": "2022-01-19T21:53:30.226650Z",
     "iopub.status.idle": "2022-01-19T21:53:30.235797Z",
     "shell.execute_reply": "2022-01-19T21:53:30.235114Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.226873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.238740Z",
     "iopub.status.busy": "2022-01-19T21:53:30.238380Z",
     "iopub.status.idle": "2022-01-19T21:53:30.245614Z",
     "shell.execute_reply": "2022-01-19T21:53:30.244877Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.238623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# font configuration\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Data Preparation**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.247562Z",
     "iopub.status.busy": "2022-01-19T21:53:30.247269Z",
     "iopub.status.idle": "2022-01-19T21:53:30.616724Z",
     "shell.execute_reply": "2022-01-19T21:53:30.615975Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.247522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = pd.read_csv(\"../input/btcusdt/btcusd_1-min_data.csv\")\n",
    "columns_dict = {'t': 'Unix_timestamp',\n",
    "                'o': 'Opening_price',\n",
    "                'h': 'Highest_price',\n",
    "                'l': 'Lowest_price',\n",
    "                'c': 'Closing_price',\n",
    "                'v': 'Volume_of_transactions'\n",
    "               }\n",
    "data = data.rename(columns=columns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.619086Z",
     "iopub.status.busy": "2022-01-19T21:53:30.618650Z",
     "iopub.status.idle": "2022-01-19T21:53:30.637584Z",
     "shell.execute_reply": "2022-01-19T21:53:30.636828Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.619047Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6750281 entries, 0 to 6750280\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   Unix_timestamp          float64\n",
      " 1   Opening_price           float64\n",
      " 2   Highest_price           float64\n",
      " 3   Lowest_price            float64\n",
      " 4   Closing_price           float64\n",
      " 5   Volume_of_transactions  float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 309.0 MB\n"
     ]
    }
   ],
   "source": [
    "# show info of data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.639168Z",
     "iopub.status.busy": "2022-01-19T21:53:30.638913Z",
     "iopub.status.idle": "2022-01-19T21:53:30.643007Z",
     "shell.execute_reply": "2022-01-19T21:53:30.642148Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.639133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot data processing statistics\n",
    "plot_data_process = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.644995Z",
     "iopub.status.busy": "2022-01-19T21:53:30.644663Z",
     "iopub.status.idle": "2022-01-19T21:53:30.677461Z",
     "shell.execute_reply": "2022-01-19T21:53:30.676754Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.644960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sort datapoints by timestamp\n",
    "data = data.sort_values('Unix_timestamp', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.679374Z",
     "iopub.status.busy": "2022-01-19T21:53:30.678886Z",
     "iopub.status.idle": "2022-01-19T21:53:30.699528Z",
     "shell.execute_reply": "2022-01-19T21:53:30.698856Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.679337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # converts format from unix to UTC+8\\ndata['Unix_timestamp'] = pd.to_datetime(data['Unix_timestamp'], unit='s') + pd.Timedelta('08:00:00')\\ndata = data.rename(columns={'Unix_timestamp': 'Timestamp'})\\nprint(data.head()) \""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # converts format from unix to UTC+8\n",
    "data['Unix_timestamp'] = pd.to_datetime(data['Unix_timestamp'], unit='s') + pd.Timedelta('08:00:00')\n",
    "data = data.rename(columns={'Unix_timestamp': 'Timestamp'})\n",
    "print(data.head()) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据框的所有列名:\n",
      "['Unix_timestamp', 'Opening_price', 'Highest_price', 'Lowest_price', 'Closing_price', 'Volume_of_transactions']\n",
      "删除异常值前的行数: 6750281\n",
      "删除异常值后的行数: 6750279\n",
      "\n",
      "处理后的前5行数据:\n",
      "            Timestamp  Opening_price  Highest_price  Lowest_price  \\\n",
      "0 2012-01-01 18:01:00           4.58           4.58          4.58   \n",
      "1 2012-01-01 18:02:00           4.58           4.58          4.58   \n",
      "2 2012-01-01 18:03:00           4.58           4.58          4.58   \n",
      "3 2012-01-01 18:05:00           4.58           4.58          4.58   \n",
      "4 2012-01-01 18:06:00           4.58           4.58          4.58   \n",
      "\n",
      "   Closing_price  Volume_of_transactions  \n",
      "0           4.58                     0.0  \n",
      "1           4.58                     0.0  \n",
      "2           4.58                     0.0  \n",
      "3           4.58                     0.0  \n",
      "4           4.58                     0.0  \n",
      "\n",
      "数据时间范围:\n",
      "起始时间: 2012-01-01 18:01:00\n",
      "结束时间: 2025-01-27 08:00:00\n",
      "            Timestamp  Opening_price  Highest_price  Lowest_price  \\\n",
      "0 2012-01-01 18:01:00           4.58           4.58          4.58   \n",
      "1 2012-01-01 18:02:00           4.58           4.58          4.58   \n",
      "2 2012-01-01 18:03:00           4.58           4.58          4.58   \n",
      "3 2012-01-01 18:05:00           4.58           4.58          4.58   \n",
      "4 2012-01-01 18:06:00           4.58           4.58          4.58   \n",
      "\n",
      "   Closing_price  Volume_of_transactions  \n",
      "0           4.58                     0.0  \n",
      "1           4.58                     0.0  \n",
      "2           4.58                     0.0  \n",
      "3           4.58                     0.0  \n",
      "4           4.58                     0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"数据框的所有列名:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "\n",
    "# converts format from unix to UTC+8\n",
    "data['Unix_timestamp'] = pd.to_datetime(data['Unix_timestamp'], unit='s') + pd.Timedelta('08:00:00')\n",
    "data = data.rename(columns={'Unix_timestamp': 'Timestamp'})\n",
    "# 1. 检查并删除错误的时间戳行\n",
    "print(\"删除异常值前的行数:\", len(data))\n",
    "data = data[data['Timestamp'].dt.year >= 2012]\n",
    "print(\"删除异常值后的行数:\", len(data))\n",
    "\n",
    "# 2. 重置索引\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# 3. 验证结果\n",
    "print(\"\\n处理后的前5行数据:\")\n",
    "print(data.head())\n",
    "\n",
    "# 4. 查看时间范围\n",
    "print(\"\\n数据时间范围:\")\n",
    "print(\"起始时间:\", data['Timestamp'].min())\n",
    "print(\"结束时间:\", data['Timestamp'].max())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:53:30.702929Z",
     "iopub.status.busy": "2022-01-19T21:53:30.702718Z",
     "iopub.status.idle": "2022-01-19T21:54:48.135364Z",
     "shell.execute_reply": "2022-01-19T21:54:48.134596Z",
     "shell.execute_reply.started": "2022-01-19T21:53:30.702904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages\\finta\\finta.py:399: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for x, y in zip(x.fillna(0).iteritems(), y.iteritems()):\n",
      "c:\\Users\\23695\\PycharmProjects\\-Bitcoin-Price-Prediction-Using-Transformers\\.venv\\Lib\\site-packages\\finta\\finta.py:399: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for x, y in zip(x.fillna(0).iteritems(), y.iteritems()):\n"
     ]
    }
   ],
   "source": [
    "# add finta features\n",
    "def add_finta_feature(data, data_finta ,feature_names, both_columns_features):\n",
    "    \"\"\"Adds new fanta features to data by their feature_name in feature_names\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame, where the feature will be added\n",
    "        data_finta: DataFrame, columns' names are: 'open', 'high', 'low', 'close' and 'volume'(optinal)\n",
    "                    from which the new feature will be calculated\n",
    "        feature_names: list of strings, names of the new features you want to add\n",
    "        both_columns_features: list of strings, names of the new features you want to add both of their outputs\n",
    "    \"\"\"\n",
    "    for feature_name in feature_names:\n",
    "        feature_func = getattr(TA, feature_name)\n",
    "        finta_feature = feature_func(data_finta) \n",
    "        if finta_feature.ndim > 1:\n",
    "            if feature_name in both_columns_features:\n",
    "                data[\"{}_1\".format(feature_name)] = finta_feature.iloc[:, 0]\n",
    "                data[\"{}_2\".format(feature_name)] = finta_feature.iloc[:, 1]\n",
    "            else:\n",
    "                data[feature_name] = finta_feature.iloc[:, 0]\n",
    "        else:\n",
    "            data[feature_name] = finta_feature\n",
    "        \n",
    "# Finta needs specific columns' names to work\n",
    "data_finta = pd.DataFrame()\n",
    "data_finta['open'] = data['Opening_price']\n",
    "data_finta['high'] = data['Highest_price']\n",
    "data_finta['low'] = data['Lowest_price']\n",
    "data_finta['close'] = data['Closing_price']\n",
    "data_finta['volume'] = data['Volume_of_transactions']\n",
    "\n",
    "# create data with all wanted features per minute\n",
    "data_min = data.copy()\n",
    "extra_features = ['TRIX', 'VWAP', 'MACD', 'EV_MACD', 'MOM', 'RSI', 'IFT_RSI', 'TR', 'ATR', 'BBWIDTH', 'DMI', 'ADX', 'STOCHRSI',\n",
    "                  'MI', 'CHAIKIN', 'VZO', 'PZO', 'EFI', 'EBBP', 'BASP', 'BASPN', 'WTO', 'SQZMI', 'VFI', 'STC']\n",
    "both_columns_features = [\"DMI\", \"EBBP\", \"BASP\", \"BASPN\"]\n",
    "add_finta_feature(data_min, data_finta, extra_features, both_columns_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.137152Z",
     "iopub.status.busy": "2022-01-19T21:54:48.136889Z",
     "iopub.status.idle": "2022-01-19T21:54:48.189229Z",
     "shell.execute_reply": "2022-01-19T21:54:48.188493Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.137115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find the maximum index containing NaN\n",
    "if plot_data_process:\n",
    "    print(\"Last index containing NaN in each feature:\")\n",
    "max_index = -np.inf\n",
    "for column in data_min.columns:\n",
    "    nan_indices = data_min[column].index[data_min[column].apply(np.isnan)]\n",
    "    max_index_column = np.max(nan_indices)\n",
    "    if plot_data_process:\n",
    "        print(\"\\t\", column, \":\", max_index_column)\n",
    "    if max_index_column > max_index:\n",
    "        max_index = max_index_column\n",
    "if plot_data_process:\n",
    "    print(\"\\nLast index containing NaN in all data:\", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.190575Z",
     "iopub.status.busy": "2022-01-19T21:54:48.190333Z",
     "iopub.status.idle": "2022-01-19T21:54:48.476470Z",
     "shell.execute_reply": "2022-01-19T21:54:48.475605Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.190541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# drop the rows up to the last Nans in data of minutes - 131 minutes\n",
    "start_index = max_index + 1\n",
    "data_min = data_min.iloc[start_index: , :]\n",
    "data_min = data_min.reset_index(drop=True)\n",
    "start_hour = start_index // 60\n",
    "start_minute = start_index % 60\n",
    "# Drop Non-numeric columns\n",
    "data_min.drop(['Timestamp'], inplace=True, axis=1)\n",
    "\n",
    "# reorder columns by importance:\n",
    "new_columns_order = ['Closing_price', 'Volume_of_transactions', 'Opening_price', 'Highest_price', 'Lowest_price','TRIX', 'VWAP', 'MACD',\n",
    "                     'EV_MACD', 'MOM', 'RSI', 'IFT_RSI', 'TR', 'ATR', 'BBWIDTH', 'DMI_1', 'DMI_2', 'ADX', 'STOCHRSI', 'MI', 'CHAIKIN', \n",
    "                     'VZO', 'PZO', 'EFI', 'EBBP_1', 'EBBP_2', 'BASP_1', 'BASP_2', 'BASPN_1', 'BASPN_2', 'WTO', 'SQZMI', 'VFI', 'STC']\n",
    "data_min = data_min[new_columns_order]\n",
    "# show info of data - now there are no Nans\n",
    "if plot_data_process:\n",
    "    data_min.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Model and Functions Definition**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.478213Z",
     "iopub.status.busy": "2022-01-19T21:54:48.477539Z",
     "iopub.status.idle": "2022-01-19T21:54:48.484986Z",
     "shell.execute_reply": "2022-01-19T21:54:48.484148Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.478180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split the data to train, validation and test\n",
    "def train_validation_test_split(data, val_percentage, test_percentage):\n",
    "    \"\"\"Splits the data into train, validation and test\n",
    "\n",
    "    Args:\n",
    "        data: Tensor, shape [N, E]\n",
    "        val_percentage: float, validation percentage from the data [0,1]\n",
    "        test_percentage: float, test percentage from the data (0,1]\n",
    "    Returns:\n",
    "        train: Tensor, shape [N - N * (val_percentage + test_percentage), E]\n",
    "        val: Tensor, shape [N * val_percentage, E] or None if val_percentage = 0\n",
    "        test: Tensor, shape [N * test_percentage, E]\n",
    "    \"\"\"\n",
    "    data_length = len(data)\n",
    "    \n",
    "    val_length = int(data_length * val_percentage)\n",
    "    test_length = int(data_length * test_percentage)\n",
    "    train_length = data_length - val_length - test_length\n",
    "    \n",
    "    train = data[:train_length]\n",
    "    if val_length == 0:\n",
    "        val = None\n",
    "    else:\n",
    "        val = data[train_length:train_length+val_length]\n",
    "    test = data[train_length+val_length:]\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.487622Z",
     "iopub.status.busy": "2022-01-19T21:54:48.486908Z",
     "iopub.status.idle": "2022-01-19T21:54:48.496602Z",
     "shell.execute_reply": "2022-01-19T21:54:48.495743Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.487572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(train, val ,test ,scaler=pp.StandardScaler()):\n",
    "    \"\"\"Scale the data: train, val and test according to train\n",
    "\n",
    "    Args:\n",
    "        train: Tensor, shape [N_train, E]\n",
    "        val: Tensor, shape [N_val, E] (supports val=None)\n",
    "        test: Tensor, shape [N_test, E]\n",
    "        scaler: function, scaling function\n",
    "    Returns:\n",
    "        train: Tensor, shape [N_train, E]\n",
    "        val: Tensor, shape [N_val, E]\n",
    "        test: Tensor, shape [N_test, E]\n",
    "        fitted_scaler: function, scaler fitted to train\n",
    "    \"\"\"\n",
    "    fitted_scaler = scaler.fit(train)\n",
    "    train = torch.tensor(fitted_scaler.transform(train))\n",
    "    if val is not None:\n",
    "        val = torch.tensor(fitted_scaler.transform(val))\n",
    "\n",
    "    test = torch.tensor(fitted_scaler.transform(test))\n",
    "\n",
    "    return train, val, test, fitted_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.498425Z",
     "iopub.status.busy": "2022-01-19T21:54:48.497978Z",
     "iopub.status.idle": "2022-01-19T21:54:48.506940Z",
     "shell.execute_reply": "2022-01-19T21:54:48.506128Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.498388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def betchify(data, batch_size):\n",
    "    \"\"\"Divides the data into batch_size separate sequences, \n",
    "    removing extra elements that wouldn't cleanly fit.\n",
    "\n",
    "    Args:\n",
    "        data: Tensor, shape [N, E]\n",
    "        batch_size: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape [N // batch_size, batch_size, E]\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // batch_size\n",
    "    data = data[:seq_len * batch_size,:]\n",
    "    data = data.view(batch_size, seq_len, -1)\n",
    "    data = torch.transpose(data,0,1).contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.509048Z",
     "iopub.status.busy": "2022-01-19T21:54:48.508228Z",
     "iopub.status.idle": "2022-01-19T21:54:48.518921Z",
     "shell.execute_reply": "2022-01-19T21:54:48.518225Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.508974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_batch(data, i, bptt_src, bptt_tgt, overlap):\n",
    "    \"\"\"Divides data to source and target, from offset i\n",
    "    \n",
    "    Args:\n",
    "        source: Tensor, shape [N, batch_size, E]\n",
    "        i: int, offset for the source\n",
    "        bptt_src: int, size of back propagation through time, sequence length of source\n",
    "        bptt_tgt: int, size of back propagation through time, sequence length of target\n",
    "        overlap: int, number of overlapping elements between source and target\n",
    "\n",
    "    Returns:\n",
    "        source: Tensor, shape [bptt_src, batch_size, E]\n",
    "        target: Tensor, shape [bptt_tgt, batch_size, E]\n",
    "    \"\"\"\n",
    "    src_seq_len = min(bptt_src, len(data) - i - 1)\n",
    "    target_seq_len = min(bptt_tgt, len(data) - i - src_seq_len + overlap)\n",
    "    source = data[i: i + src_seq_len]\n",
    "    target = data[i + src_seq_len - overlap: i + src_seq_len + target_seq_len - overlap]\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.520970Z",
     "iopub.status.busy": "2022-01-19T21:54:48.520439Z",
     "iopub.status.idle": "2022-01-19T21:54:48.532070Z",
     "shell.execute_reply": "2022-01-19T21:54:48.531348Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.520932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SineActivation(nn.Module):\n",
    "    def __init__(self, in_features, periodic_features, out_features, dropout):\n",
    "        super(SineActivation, self).__init__()\n",
    "        # weights and biases for the periodic features\n",
    "        self.w0 = nn.parameter.Parameter(torch.randn(in_features, out_features - in_features - periodic_features))\n",
    "        self.b0 = nn.parameter.Parameter(torch.randn(1, out_features - in_features - periodic_features))\n",
    "        # weights and biases for the linear features\n",
    "        self.w = nn.parameter.Parameter(torch.randn(in_features, periodic_features))\n",
    "        self.b = nn.parameter.Parameter(torch.randn(1, periodic_features))\n",
    "        self.activation = torch.sin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def Time2Vector(self, data):\n",
    "        \"\"\"Add features to data: \n",
    "            1. keep the original features numbered by - in_features\n",
    "            2. add more periodic features numbered by - periodic_features\n",
    "            3. add more linear feature to end up with total of features numbered by - out_features\n",
    "    \n",
    "        Args:\n",
    "            data: Tensor, shape [N, batch_size, in_features]\n",
    "\n",
    "        Returns:\n",
    "            data: Tensor, shape [N, batch_size, out_features]\n",
    "        \"\"\"\n",
    "        v_linear = torch.matmul(self.w0.t(), data.transpose(1,2)).transpose(1,2) + self.b0\n",
    "        v_sin = self.activation(torch.matmul(self.w.t(), data.transpose(1,2)).transpose(1,2) + self.b)\n",
    "        data = torch.cat([v_linear, v_sin, data], 2)\n",
    "        return data\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = self.Time2Vector(data)\n",
    "        data = self.dropout(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.534846Z",
     "iopub.status.busy": "2022-01-19T21:54:48.534432Z",
     "iopub.status.idle": "2022-01-19T21:54:48.547780Z",
     "shell.execute_reply": "2022-01-19T21:54:48.547074Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.534799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BTC_Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 in_features: int,\n",
    "                 periodic_features: int,\n",
    "                 out_features: int,\n",
    "                 nhead: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1,\n",
    "                 activation: str = 'relu'):\n",
    "        super(BTC_Transformer, self).__init__()\n",
    "        \n",
    "        self.sine_activation = SineActivation(in_features=in_features,\n",
    "                                              periodic_features=periodic_features,\n",
    "                                              out_features=out_features,\n",
    "                                              dropout=dropout)\n",
    "        \n",
    "        self.transformer = nn.Transformer(d_model=out_features,\n",
    "                                          nhead=nhead,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,\n",
    "                                          activation=activation)\n",
    "        \n",
    "        self.generator = nn.Linear(out_features, in_features)\n",
    "    \n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.sine_activation(src), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.sine_activation(tgt), memory, tgt_mask)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor=None,\n",
    "                tgt_mask: Tensor=None,\n",
    "                mem_mask: Tensor=None,\n",
    "                src_padding_mask: Tensor=None,\n",
    "                tgt_padding_mask: Tensor=None,\n",
    "                memory_key_padding_mask: Tensor=None):\n",
    "        \n",
    "        src_emb = self.sine_activation(src)\n",
    "        tgt_emb = self.sine_activation(trg)\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, mem_mask,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.549859Z",
     "iopub.status.busy": "2022-01-19T21:54:48.549570Z",
     "iopub.status.idle": "2022-01-19T21:54:48.561772Z",
     "shell.execute_reply": "2022-01-19T21:54:48.561063Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.549806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data, bptt_src, bptt_tgt, overlap, criterion, predicted_feature):\n",
    "    \"\"\"run the data through the model in eval mode and calculate the average loss in the given feature\n",
    "    \n",
    "    Args:\n",
    "        model: nn.Module, the model you want to run the data in\n",
    "        data: Tensor, shape [N, batch_size, E]\n",
    "        bptt_src: int, size of back propagation through time, sequence length of source\n",
    "        bptt_tgt: int, size of back propagation through time, sequence length of target\n",
    "        overlap: int, number of overlapping elements between source and target\n",
    "        criterion: nn.module, the loss function\n",
    "        predicted_feature: int, index of the feature you want to evaluate in [0,E-1]\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        mean_loss: float, average loss recieved over all data on the chosen feature\n",
    "    \"\"\"\n",
    "    model.eval()     # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = torch.zeros((bptt_src,bptt_src), dtype=torch.bool).to(device) # zeros mask for the source (no mask)\n",
    "    tgt_mask = model.transformer.generate_square_subsequent_mask(bptt_tgt).to(device) # look-ahead mask for the target\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data.size(0) - 1, bptt_src):\n",
    "            source, targets = get_batch(data, i, bptt_src, bptt_tgt, overlap)\n",
    "            src_batch_size = source.size(0)\n",
    "            tgt_batch_size = targets.size(0)\n",
    "            if tgt_batch_size != bptt_tgt or src_batch_size != bptt_src:  # only on last batch\n",
    "                src_mask = src_mask[:src_batch_size, :src_batch_size]\n",
    "                tgt_mask = tgt_mask[:tgt_batch_size, :tgt_batch_size]       \n",
    "            output = model(source, targets, src_mask, tgt_mask)\n",
    "            loss = criterion(output[:-1,:,predicted_feature], targets[1:,:,predicted_feature])\n",
    "            total_loss += len(source) * loss.item()\n",
    "    mean_loss = total_loss / (len(data) - 1)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Data Separation to train-test-validation**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.563774Z",
     "iopub.status.busy": "2022-01-19T21:54:48.563242Z",
     "iopub.status.idle": "2022-01-19T21:54:48.575117Z",
     "shell.execute_reply": "2022-01-19T21:54:48.574142Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.563733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "val_percentage = 0.1\n",
    "test_percentage = 0.1\n",
    "train_df, val_df, test_df = train_validation_test_split(data_min, val_percentage, test_percentage)\n",
    "print(np.shape(train_df))\n",
    "if val_df is not None:\n",
    "    print(np.shape(val_df))\n",
    "print(np.shape(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:48.577235Z",
     "iopub.status.busy": "2022-01-19T21:54:48.576836Z",
     "iopub.status.idle": "2022-01-19T21:54:49.192549Z",
     "shell.execute_reply": "2022-01-19T21:54:49.191844Z",
     "shell.execute_reply.started": "2022-01-19T21:54:48.577199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot train, validation and test separation\n",
    "if plot_data_process:\n",
    "    train_time = np.arange(np.size(train_df, 0))\n",
    "    if val_df is not None:\n",
    "        val_time = np.arange(np.size(train_df, 0), np.size(train_df, 0) + np.size(val_df, 0))\n",
    "        test_time = np.arange(np.size(train_df, 0) + np.size(val_df, 0), np.size(train_df, 0) + np.size(val_df, 0) + np.size(test_df, 0))\n",
    "    else:\n",
    "        test_time = np.arange(np.size(train_df, 0), np.size(train_df, 0) + np.size(test_df, 0))\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    st = fig.suptitle(\"Data Separation\", fontsize=20)\n",
    "    ax = fig.add_subplot(1, 1 ,1)\n",
    "    ax.set_xlabel(\"Time - Minutes From (UTC+8): 2021-01-01 {:02d}:{:02d}:00\".format(start_hour, start_minute))     \n",
    "    ax.set_ylabel(\"Closing Price [USD]\")            \n",
    "    ax.set_title(\"Closing Price Through Time\")\n",
    "    ax.plot(train_time, train_df['Closing_price'], label='Training data')\n",
    "    if val_df is not None:\n",
    "        ax.plot(val_time, val_df['Closing_price'], label='Validation data')\n",
    "    ax.plot(test_time, test_df['Closing_price'], label='Test data')\n",
    "    ax.grid()\n",
    "    ax.legend(loc=\"best\", fontsize=12) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Optuna hyper-parameter optimization**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:49.193857Z",
     "iopub.status.busy": "2022-01-19T21:54:49.193595Z",
     "iopub.status.idle": "2022-01-19T21:54:49.201963Z",
     "shell.execute_reply": "2022-01-19T21:54:49.201037Z",
     "shell.execute_reply.started": "2022-01-19T21:54:49.193806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# declaration of the define_model class for optuna\n",
    "def define_model(trial):\n",
    "    num_encoder_layers = trial.suggest_int(\"encoder_layers\", 4, 8, step=4)\n",
    "    num_decoder_layers = num_encoder_layers\n",
    "    in_features = 34\n",
    "    out_features = trial.suggest_int(\"out_features\", 36, 64, step=4)\n",
    "    nhead = int(out_features / 4)\n",
    "    dim_feedforward = trial.suggest_int(\"dim_feedforward\", 128, 512, step=128)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3, step=0.1)\n",
    "    activation =  trial.suggest_categorical(\"activation\", [\"relu\", \"gelu\"])\n",
    "    periodic_features = int((((out_features - in_features) // 10) * 4) + 2)\n",
    "    \n",
    "    return BTC_Transformer(\n",
    "                            num_encoder_layers=num_encoder_layers,\n",
    "                            num_decoder_layers=num_decoder_layers,\n",
    "                            in_features=in_features,\n",
    "                            periodic_features=periodic_features,\n",
    "                            out_features=out_features,\n",
    "                            nhead=nhead,\n",
    "                            dim_feedforward=dim_feedforward,\n",
    "                            dropout=dropout,\n",
    "                            activation=activation\n",
    "        \n",
    "                            ).to(device), in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:49.203713Z",
     "iopub.status.busy": "2022-01-19T21:54:49.203447Z",
     "iopub.status.idle": "2022-01-19T21:54:49.228375Z",
     "shell.execute_reply": "2022-01-19T21:54:49.227591Z",
     "shell.execute_reply.started": "2022-01-19T21:54:49.203677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# declaration of the objective class for optuna\n",
    "def objective(trial):\n",
    "    # split the data\n",
    "    val_percentage = 0.1\n",
    "    test_percentage = 0.1\n",
    "    train_, val_, test_ = train_validation_test_split(data_min, val_percentage, test_percentage)\n",
    "\n",
    "    # define the parameters\n",
    "    overlap = 1\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    in_features = 34\n",
    "    num_features = in_features\n",
    "    step_size = 1.0\n",
    "\n",
    "    epochs = 50 \n",
    "       \n",
    "    train_batch_size = 32 \n",
    "    eval_batch_size = 32 \n",
    "    \n",
    "    bptt_src = trial.suggest_int(\"bptt_src\", 10, 60, step=10)\n",
    "    bptt_tgt = trial.suggest_int(\"bptt_tgt\", 2, 18, step=2)\n",
    "    \n",
    "    lr = 0.5 \n",
    "    optimizer_name = \"SGD\" \n",
    "    \n",
    "    scaler_name = trial.suggest_categorical(\"scaler_name\", [\"standard\", \"minmax\"])\n",
    "    \n",
    "    gamma = 0.95 \n",
    "    \n",
    "    clip_param = trial.suggest_float(\"clip_param\", 0.25, 1, step=0.25)\n",
    "    \n",
    "    random_start_point = trial.suggest_categorical(\"random_start_point\", [\"True\", \"False\"])\n",
    "    \n",
    "    # define the model\n",
    "    model, in_features = define_model(trial)\n",
    "    num_features = in_features\n",
    "    \n",
    "    # define the optimizer\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    # define the scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=gamma)\n",
    "    \n",
    "    # define the scaler\n",
    "    if scaler_name == 'standard':\n",
    "        scaler = pp.StandardScaler()\n",
    "    if scaler_name == 'minmax':\n",
    "        scaler = pp.MinMaxScaler()\n",
    "        \n",
    "    # create the relevant data\n",
    "    train = train_df.iloc[:, :num_features]\n",
    "    if val_df is not None:\n",
    "        val = val_df.iloc[:, :num_features]\n",
    "    else:\n",
    "        val = val_df\n",
    "    test = test_df.iloc[:, :num_features]\n",
    "    train, val ,test ,scaler = normalize_data(train, val ,test ,scaler)\n",
    "    train_data = betchify(train, train_batch_size).float()\n",
    "    if val is not None:\n",
    "        val_data = betchify(val, eval_batch_size).float()\n",
    "    test_data = betchify(test, eval_batch_size).float()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # epoch initialization\n",
    "        model.train()\n",
    "        total_loss = 0.\n",
    "        epoch_loss = 0.\n",
    "\n",
    "        # start point of the data\n",
    "        if random_start_point:\n",
    "            start_point = np.random.randint(bptt_src)\n",
    "        else:\n",
    "            start_point = 0\n",
    "\n",
    "        num_batches = (len(train_data) - start_point) // bptt_src\n",
    "        log_interval = round(num_batches // 3 / 10) * 10\n",
    "\n",
    "        # masks for the model \n",
    "        src_mask = torch.zeros((bptt_src,bptt_src), dtype=torch.bool).to(device) # zeros mask for the source (no mask)\n",
    "        tgt_mask = model.transformer.generate_square_subsequent_mask(bptt_tgt).to(device) # look-ahead mask for the target\n",
    "\n",
    "\n",
    "        for batch, i in enumerate(range(start_point, train_data.size(0) - 1, bptt_src)):\n",
    "            # forward\n",
    "            source, targets = get_batch(train_data, i, bptt_src, bptt_tgt, overlap)\n",
    "            src_batch_size = source.size(0)\n",
    "            tgt_batch_size = targets.size(0)\n",
    "            if tgt_batch_size != bptt_tgt or src_batch_size != bptt_src:  # only on last batch\n",
    "                src_mask = src_mask[:src_batch_size, :src_batch_size]\n",
    "                tgt_mask = tgt_mask[:tgt_batch_size, :tgt_batch_size]\n",
    "            output = model(source, targets, src_mask, tgt_mask)\n",
    "            loss = criterion(output[:-1,:,predicted_feature], targets[1:,:,predicted_feature])\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_param)\n",
    "\n",
    "            # step\n",
    "            optimizer.step()\n",
    "\n",
    "            # record bacth statistics\n",
    "            total_loss += loss.item()\n",
    "            epoch_loss += len(source) * loss.item()\n",
    "\n",
    "            # print statistics every log_interval\n",
    "            if (batch % log_interval == 0) and batch > 0:\n",
    "                lr = scheduler.get_last_lr()[0]\n",
    "                cur_loss = total_loss / log_interval\n",
    "                total_loss = 0\n",
    "\n",
    "        # evaluate on validation and save best model\n",
    "        if val is not None:\n",
    "            val_loss = evaluate(model, val_data, bptt_src, bptt_tgt, overlap, criterion, predicted_feature)\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "            \n",
    "            # report results of optuna trial\n",
    "            trial.report(val_loss, epoch)  \n",
    "\n",
    "            # cut trial if we get bad results\n",
    "            if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        # scheduler step\n",
    "        scheduler.step()\n",
    "\n",
    "    if val is None:\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T21:54:49.229901Z",
     "iopub.status.busy": "2022-01-19T21:54:49.229634Z",
     "iopub.status.idle": "2022-01-20T04:07:56.821966Z",
     "shell.execute_reply": "2022-01-20T04:07:56.821304Z",
     "shell.execute_reply.started": "2022-01-19T21:54:49.229867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_feature = train_df.columns.get_loc('Closing_price')\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(study_name=\"BTC_Transformer\", direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"Number of finished trials: \",len(study.trials))\n",
    "print(\"Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"Number of complete trials: \", len(complete_trials))\n",
    "print(\"Best trial: \")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"Value: \", trial.value)\n",
    "print(\"Params: \")\n",
    "for key, value in trial.params.iteritems():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**Visualization**</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check which parameter is the most effective\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"encoder_layers\", \"out_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"out_features\", \"dim_feedforward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"dim_feedforward\", \"dropout\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"dropout\", \"activation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"activation\", \"bptt_src\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"bptt_src\", \"bptt_tgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualizing the Search Space\n",
    "optuna.visualization.plot_contour(study, params=[\"bptt_tgt\", \"clip_param\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
